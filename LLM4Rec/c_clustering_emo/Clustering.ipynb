{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from get_embedding import getEmbeddingDict\n",
    "\n",
    "corpus_path = \"corpus/emo_map_list.txt\"\n",
    "aug_corpus_path = \"corpus/2_aug_emo_map_list.txt\"\n",
    "embedding_path = \"embedding/emomap_embeddings_ada002.json\"\n",
    "aug_embedding_path = \"embedding/aug_emomap_embeddings_ada002.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature\n",
    "def data_augmentation(corpus, scale):\n",
    "    with open(corpus, 'r') as f:\n",
    "        words = eval(f.read())\n",
    "    aug_words = [word.strip() * scale for word in words]\n",
    "\n",
    "    aug_path = f\"corpus/{scale}_aug_emo_map_list.txt\"\n",
    "    with open(aug_path, \"w\") as f:\n",
    "        f.write(str(aug_words))\n",
    "    \n",
    "    print(\"the augmented data is stored in: \", aug_path)\n",
    "\n",
    "def dim_reduction(n_components, embedding_dict): # input: dict; output: dict\n",
    "    keys = list(embedding_dict.keys())\n",
    "    embeddings = list(embedding_dict.values())\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_embeddings = pca.fit_transform(embeddings).tolist()\n",
    "    pca_embedding_dict = dict(zip(keys, pca_embeddings))\n",
    "    return pca_embedding_dict\n",
    "\n",
    "def kmeans_cls(num_clusters, tags, embeddings): # K-means\n",
    "\n",
    "    print('cluster=', num_clusters)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(embeddings)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    return dict(zip(tags, cluster_labels))\n",
    "\n",
    "emo_embedding_dict = getEmbeddingDict(corpus_path, embedding_path)\n",
    "augemo_embedding_dict = getEmbeddingDict(aug_corpus_path, aug_embedding_path)\n",
    "pca_embedding_dict = dim_reduction(150, emo_embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster= 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "## Kmeans Clustering\n",
    "a = kmeans_cls(150, list(pca_embedding_dict.keys()), list(pca_embedding_dict.values()))\n",
    "emotion_df = pd.DataFrame(list(a.items()), columns=['tags_emotion', 'label'])\n",
    "emotion_df.sort_values('label').to_excel('emotion_cluster.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Supervised Classification\n",
    "df = pd.read_excel('data/emotion_keep.xlsx')\n",
    "df['tags_emotion'] = df['tags_emotion'].map(pca_embedding_dict)\n",
    "df = df[['tags_emotion', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pcaemo_center_embedding.json', 'r') as file:\n",
    "    cluster_centers_data = json.load(file)\n",
    "with open('pcaemo_embeddings_ada002.json', 'r') as file:\n",
    "    embeddings_data = json.load(file)\n",
    "\n",
    "cluster_centers_data_sample = {k: cluster_centers_data[k] for k in list(cluster_centers_data)[:5]}\n",
    "embeddings_data_sample = {k: embeddings_data[k] for k in list(embeddings_data)[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corpus_path, 'r') as f:\n",
    "    tags = eval(f.read()) # load theme tags\n",
    "unique_tags = list(set(tags)) # unique tags\n",
    "\n",
    "# LLM-ada002 configuration\n",
    "embedding = OpenAIEmbeddings(\n",
    "    deployment = \"embedding-ada-002-2\",\n",
    "    model = \"text-embedding-ada-002\",\n",
    "    openai_api_key = \"6e25ec6fa59d44f8af091db59e6db6d7\",\n",
    "    openai_api_base = 'https://tcl-ai.openai.azure.com/',\n",
    "    openai_api_type = 'azure',\n",
    "    openai_api_version = '2023-07-01-preview',\n",
    "    chunk_size=1,\n",
    ")\n",
    "\n",
    "# generate LLM-ada002 embedding\n",
    "tag_documents = unique_tags\n",
    "tag_embeddings = embedding.embed_documents(tag_documents)\n",
    "\n",
    "# save LLM-ada002 embedding\n",
    "embedding_dictionary = {}\n",
    "for tagDoc, tagEmbedding in zip(tag_documents, tag_embeddings):\n",
    "    embedding_dictionary[tagDoc] = (tagEmbedding)\n",
    "file_path = embedding_path\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(embedding_dictionary, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedding/emo_center_embedding.json', 'r') as f:\n",
    "    theme_embeddings_dict = json.load(f)\n",
    "    pca_embedding_dict = dim_reduction(10, theme_embeddings_dict)\n",
    "with open('emo_center_embedding.json', 'w') as json_file:\n",
    "        json.dump(pca_embedding_dict, json_file)\n",
    "with open('embedding/emomap_embeddings_ada002.json', 'r') as f:\n",
    "    theme_embeddings_dict = json.load(f)\n",
    "    pca_embedding_dict = dim_reduction(10, theme_embeddings_dict)\n",
    "with open('pcaemo_embeddings_ada002.json', 'w') as json_file:\n",
    "        json.dump(pca_embedding_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = list(cluster_centers_data.values())\n",
    "\n",
    "embeddings = list(embeddings_data.values())\n",
    "embedding_keys = list(embeddings_data.keys())\n",
    "\n",
    "distances = cdist(embeddings, cluster_centers, 'euclidean')\n",
    "closest_cluster_indices = np.argmin(distances, axis=1)\n",
    "\n",
    "cluster_names = list(cluster_centers_data.keys())\n",
    "classified_embeddings = {embedding_keys[i]: cluster_names[closest_cluster_indices[i]] for i in range(len(embedding_keys))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.DataFrame(list(classified_embeddings.items()), columns=['Key', 'Cluster'])\n",
    "df_embeddings.sort_values('Cluster').to_excel('emotion_class.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "\n",
    "tuple_pca_embedding_dict = {k: tuple(v) for k, v in pca_embedding_dict.items()}\n",
    "inverse_pca_embedding_dict = {v: k for k, v in tuple_pca_embedding_dict.items()}\n",
    "df['tags_emotion'] = df['tags_emotion'].apply(lambda x: inverse_pca_embedding_dict[tuple(x)] if tuple(x) in inverse_pca_embedding_dict else None)\n",
    "df = df[['tags_emotion', 'label', 'predicted_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/emotion_human.xlsx')\n",
    "df['tags_emotion'] = df['tags_emotion'].map(pca_embedding_dict)\n",
    "df = df[['tags_emotion', 'label']]\n",
    "# df.to_excel('example.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  2,  1, -1]),\n",
       " list,\n",
       " [0.13341506551551466, 0.1432317717360748, -0.03549755231311173])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for unique values in the 'label' column to identify if there are unlabeled instances\n",
    "data = df\n",
    "unique_labels = data['label'].unique()\n",
    "# Determine the format of the 'tags_emotion' entries\n",
    "first_entry = data['tags_emotion'][0]\n",
    "(unique_labels, type(first_entry), first_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                        tags_emotion  label\n",
       " 0  [0.13341506551551466, 0.1432317717360748, -0.0...      0\n",
       " 1  [-0.09357420371434641, -0.0716346806852909, 0....      2\n",
       " 2  [-0.0925421567144721, 0.0029044354921829853, 0...      2\n",
       " 3  [0.011553421165230922, -0.14130647648026587, 0...      0\n",
       " 4  [-0.15345890136918972, 0.09529602782552032, -0...      2,\n",
       "                                          tags_emotion  label\n",
       " 35  [0.07027609450656774, -0.007064140992634334, -...     -1\n",
       " 36  [0.10195614545193399, -0.05001554543857868, -0...     -1\n",
       " 37  [0.09053770850020393, -0.12463684019605807, 0....     -1\n",
       " 38  [-0.11437076270344095, 0.11104853225452627, -0...     -1\n",
       " 39  [0.08974735908814718, 0.10794493759273345, -0....     -1,\n",
       " (35, 2),\n",
       " (157, 2))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Separate the labeled and unlabeled data\n",
    "labeled_data = data[data['label'] != -1]\n",
    "unlabeled_data = data[data['label'] == -1]\n",
    "\n",
    "# Check the conversion and separation\n",
    "labeled_data.head(), unlabeled_data.head(), labeled_data.shape, unlabeled_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/var/folders/8z/kr38t9vx4693jfmjj5wf0b000000gn/T/ipykernel_81295/425249277.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabeled_data['label'] = kmeans.labels_\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                          tags_emotion  label\n",
       " 187  [0.018564552356162806, 0.0507342450573382, -0....      2\n",
       " 188  [0.10348100315428825, -0.06091558393554987, -0...      2\n",
       " 189  [0.07735890584167626, 0.08248571595580048, -0....      2\n",
       " 190  [-0.11199147190327581, 0.03439855435454477, -0...      1\n",
       " 191  [0.08519220961603167, -0.05897965962294559, 0....      2,\n",
       " label\n",
       " 2    74\n",
       " 0    70\n",
       " 1    48\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Extract feature arrays\n",
    "features_labeled = np.array(labeled_data['tags_emotion'].tolist())\n",
    "features_unlabeled = np.array(unlabeled_data['tags_emotion'].tolist())\n",
    "\n",
    "# Number of unique labels in the labeled data (excluding -1)\n",
    "num_clusters = len(labeled_data['label'].unique())\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(features_unlabeled)\n",
    "\n",
    "# Assign the cluster labels to the unlabeled instances\n",
    "unlabeled_data['label'] = kmeans.labels_\n",
    "\n",
    "# Combine the labeled and newly labeled data\n",
    "combined_data = pd.concat([labeled_data, unlabeled_data], ignore_index=True)\n",
    "\n",
    "# Check the combined data\n",
    "combined_data.tail(), combined_data['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data\n",
    "\n",
    "tuple_pca_embedding_dict = {k: tuple(v) for k, v in pca_embedding_dict.items()}\n",
    "inverse_pca_embedding_dict = {v: k for k, v in tuple_pca_embedding_dict.items()}\n",
    "combined_data['tags_emotion'] = combined_data['tags_emotion'].apply(lambda x: inverse_pca_embedding_dict[tuple(x)] if tuple(x) in inverse_pca_embedding_dict else None)\n",
    "combined_data = combined_data[['tags_emotion', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_excel('example.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cq1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
