{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/cq1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from get_embedding import getEmbeddingDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3/3 [==============================] - 1s 70ms/step - loss: 2.2891 - accuracy: 0.0989 - val_loss: 2.2653 - val_accuracy: 0.0435\n",
      "Epoch 2/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 2.1570 - accuracy: 0.3736 - val_loss: 2.1860 - val_accuracy: 0.2609\n",
      "Epoch 3/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 2.0284 - accuracy: 0.4945 - val_loss: 2.0966 - val_accuracy: 0.3478\n",
      "Epoch 4/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.8850 - accuracy: 0.4945 - val_loss: 1.9972 - val_accuracy: 0.3478\n",
      "Epoch 5/30\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.7534 - accuracy: 0.5055 - val_loss: 1.9117 - val_accuracy: 0.3478\n",
      "Epoch 6/30\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.6286 - accuracy: 0.5385 - val_loss: 1.8621 - val_accuracy: 0.3478\n",
      "Epoch 7/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5109 - accuracy: 0.5385 - val_loss: 1.8508 - val_accuracy: 0.3913\n",
      "Epoch 8/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.3680 - accuracy: 0.5604 - val_loss: 1.8640 - val_accuracy: 0.3913\n",
      "Epoch 9/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.1993 - accuracy: 0.6264 - val_loss: 1.9117 - val_accuracy: 0.3043\n",
      "Epoch 10/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0431 - accuracy: 0.7253 - val_loss: 1.9862 - val_accuracy: 0.3478\n",
      "Epoch 11/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8833 - accuracy: 0.8571 - val_loss: 2.0540 - val_accuracy: 0.3043\n",
      "Epoch 12/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7474 - accuracy: 0.8901 - val_loss: 2.1051 - val_accuracy: 0.2609\n",
      "Epoch 13/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6170 - accuracy: 0.8901 - val_loss: 2.1510 - val_accuracy: 0.3043\n",
      "Epoch 14/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5030 - accuracy: 0.9231 - val_loss: 2.2325 - val_accuracy: 0.3043\n",
      "Epoch 15/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4094 - accuracy: 0.9451 - val_loss: 2.3383 - val_accuracy: 0.3043\n",
      "Epoch 16/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3372 - accuracy: 0.9560 - val_loss: 2.4441 - val_accuracy: 0.2609\n",
      "Epoch 17/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2844 - accuracy: 0.9670 - val_loss: 2.5209 - val_accuracy: 0.2609\n",
      "Epoch 18/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2399 - accuracy: 0.9780 - val_loss: 2.5561 - val_accuracy: 0.2609\n",
      "Epoch 19/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2059 - accuracy: 0.9670 - val_loss: 2.5664 - val_accuracy: 0.3043\n",
      "Epoch 20/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1691 - accuracy: 0.9890 - val_loss: 2.5599 - val_accuracy: 0.3043\n",
      "Epoch 21/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1473 - accuracy: 0.9890 - val_loss: 2.5629 - val_accuracy: 0.3043\n",
      "Epoch 22/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1323 - accuracy: 0.9890 - val_loss: 2.5807 - val_accuracy: 0.3043\n",
      "Epoch 23/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1175 - accuracy: 0.9890 - val_loss: 2.6131 - val_accuracy: 0.3043\n",
      "Epoch 24/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1027 - accuracy: 0.9890 - val_loss: 2.6522 - val_accuracy: 0.3043\n",
      "Epoch 25/30\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.0911 - accuracy: 0.9890 - val_loss: 2.6978 - val_accuracy: 0.3043\n",
      "Epoch 26/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0835 - accuracy: 0.9890 - val_loss: 2.7331 - val_accuracy: 0.3043\n",
      "Epoch 27/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0771 - accuracy: 0.9890 - val_loss: 2.7575 - val_accuracy: 0.3043\n",
      "Epoch 28/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0720 - accuracy: 0.9890 - val_loss: 2.7768 - val_accuracy: 0.3043\n",
      "Epoch 29/30\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.0674 - accuracy: 0.9890 - val_loss: 2.7960 - val_accuracy: 0.3043\n",
      "Epoch 30/30\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.0631 - accuracy: 0.9890 - val_loss: 2.8184 - val_accuracy: 0.3043\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your data here\n",
    "book_df = pd.read_excel('Book.xlsx')\n",
    "book_test_df = pd.read_excel('Book_test.xlsx')\n",
    "\n",
    "# Assume book_df has columns 'tags_emotion' and 'label'\n",
    "texts = book_df['tags_emotion'].values\n",
    "labels = book_df['label'].values\n",
    "\n",
    "# Initialize the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Tokenize the text\n",
    "sequences = [tokenizer.encode(text, add_special_tokens=True) for text in texts]\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "X = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels)\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the RNN model\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_length))\n",
    "model.add(SimpleRNN(units=64, return_sequences=False))\n",
    "model.add(Dense(units=y.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags_emotion</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>压迫</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>压抑</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>残忍</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>残暴</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>兴奋</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>喜欢</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>开心</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>沉闷</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>寻找</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>绝望</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tags_emotion  predicted_label\n",
       "0             压迫                5\n",
       "1             压抑                5\n",
       "2             残忍                5\n",
       "3             残暴                5\n",
       "4             兴奋                2\n",
       "..           ...              ...\n",
       "187           喜欢                2\n",
       "188           开心                2\n",
       "189           沉闷                2\n",
       "190           寻找                9\n",
       "191           绝望                5\n",
       "\n",
       "[192 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Tokenize and pad the \"Book_test\" data\n",
    "test_sequences = [tokenizer.encode(text, add_special_tokens=True) for text in book_test_df['tags_emotion'].values]\n",
    "X_test = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert the probabilities to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert the integer class labels to original labels\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "# Add the predicted labels to the test dataframe\n",
    "book_test_df['predicted_label'] = predicted_labels\n",
    "\n",
    "# Display the test dataframe with the predicted labels\n",
    "book_test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diction = {1:'搞笑组', 2:'情绪组', 3:'害怕组', 4:'正能量组', 5:'负能量组', 6:'烂片组', 7:'题材', 8:'主角路线', 9:'励志组', 10:'荒诞组', 11:'思考组', 12:'经典组'}\n",
    "\n",
    "df = book_test_df.sort_values('predicted_label')\n",
    "df['predicted_label'] = df['predicted_label'].map(diction)\n",
    "df = df[['tags_emotion', 'predicted_label']]\n",
    "df.to_excel('Book_output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags_emotion</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>幽默</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>幸福</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>欢乐</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>轻松</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>欢笑</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>温馨</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>感人</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>兴奋</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>喜悦</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>开心</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>治愈</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>快乐</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>惊慌</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>紧张</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>恐慌</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>感激</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>信任</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>乐观</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>友爱</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>合作</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>荣耀</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>奋斗</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>忠诚</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>勇敢</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>英勇</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>和谐</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>坚强</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>求生</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>阴森</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>善良</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>守护</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>好奇</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>训练</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>禁赛</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>贫困</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>浪漫</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>解谜</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>冷酷</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>压迫</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>欺压</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>重逢</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>嚣张</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>夺船</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>回忆</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>利用</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>讽刺</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>考验</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>争执</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>胜利</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>违法</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tags_emotion  predicted_label\n",
       "128           幽默                1\n",
       "29            幸福                2\n",
       "45            欢乐                2\n",
       "118           轻松                2\n",
       "44            欢笑                2\n",
       "80            温馨                2\n",
       "28            感人                2\n",
       "4             兴奋                2\n",
       "97            喜悦                2\n",
       "188           开心                2\n",
       "35            治愈                2\n",
       "46            快乐                2\n",
       "20            惊慌                3\n",
       "177           紧张                3\n",
       "21            恐慌                3\n",
       "166           感激                4\n",
       "72            信任                4\n",
       "169           乐观                4\n",
       "171           友爱                4\n",
       "34            合作                4\n",
       "131           荣耀                4\n",
       "185           奋斗                4\n",
       "147           忠诚                4\n",
       "10            勇敢                4\n",
       "9             英勇                4\n",
       "162           和谐                4\n",
       "54            坚强                4\n",
       "132           求生                5\n",
       "139           阴森                5\n",
       "138           善良                5\n",
       "127           守护                5\n",
       "129           好奇                5\n",
       "136           训练                5\n",
       "135           禁赛                5\n",
       "134           贫困                5\n",
       "133           浪漫                5\n",
       "137           解谜                5\n",
       "126           冷酷                5\n",
       "0             压迫                5\n",
       "124           欺压                5\n",
       "105           重逢                5\n",
       "106           嚣张                5\n",
       "107           夺船                5\n",
       "108           回忆                5\n",
       "109           利用                5\n",
       "110           讽刺                5\n",
       "111           考验                5\n",
       "112           争执                5\n",
       "125           胜利                5\n",
       "113           违法                5"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_test_df.sort_values('predicted_label').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(\n",
    "    deployment = \"embedding-ada-002-2\",\n",
    "    model = \"text-embedding-ada-002\",\n",
    "    openai_api_key = \"xxx\",\n",
    "    openai_api_base = 'https://xxxtcl-ai.openai.azure.com/',\n",
    "    openai_api_type = 'azure',\n",
    "    openai_api_version = '2023-07-01-preview',\n",
    "    chunk_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 2.3660404682159424, Validation Loss: 2.3660404682159424\n",
      "Epoch: 2, Training Loss: 2.2802655696868896, Validation Loss: 2.2802655696868896\n",
      "Epoch: 3, Training Loss: 2.2044875621795654, Validation Loss: 2.2044875621795654\n",
      "Epoch: 4, Training Loss: 2.1367127895355225, Validation Loss: 2.1367127895355225\n",
      "Epoch: 5, Training Loss: 2.0776631832122803, Validation Loss: 2.0776631832122803\n",
      "Epoch: 6, Training Loss: 2.0273358821868896, Validation Loss: 2.0273358821868896\n",
      "Epoch: 7, Training Loss: 1.9861234426498413, Validation Loss: 1.9861234426498413\n",
      "Epoch: 8, Training Loss: 1.9527579545974731, Validation Loss: 1.9527579545974731\n",
      "Epoch: 9, Training Loss: 1.9269064664840698, Validation Loss: 1.9269064664840698\n",
      "Epoch: 10, Training Loss: 1.9103070497512817, Validation Loss: 1.9103070497512817\n",
      "Epoch: 11, Training Loss: 1.8979038000106812, Validation Loss: 1.8979038000106812\n",
      "Epoch: 12, Training Loss: 1.8897784948349, Validation Loss: 1.8897784948349\n",
      "Epoch: 13, Training Loss: 1.8854632377624512, Validation Loss: 1.8854632377624512\n",
      "Epoch: 14, Training Loss: 1.881940484046936, Validation Loss: 1.881940484046936\n",
      "Epoch: 15, Training Loss: 1.8801963329315186, Validation Loss: 1.8801963329315186\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load your data\n",
    "book_df = pd.read_excel('Book.xlsx')\n",
    "book_test_df = pd.read_excel('Book_test.xlsx')\n",
    "\n",
    "# Preprocess and prepare the dataset\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(book_df['tags_emotion'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(book_df['tags_emotion'])\n",
    "sequences_test = tokenizer.texts_to_sequences(book_test_df['tags_emotion'])\n",
    "\n",
    "max_sequence_length = max(max(len(seq) for seq in sequences + sequences_test), max(filter_sizes))\n",
    "\n",
    "\n",
    "# Custom pad_sequences function\n",
    "def pad_sequences(sequences, maxlen):\n",
    "    padded_sequences = np.zeros((len(sequences), maxlen), dtype=int)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if len(seq) == 0:  # Check for empty sequences\n",
    "            continue  # Skip padding for this sequence, it's already all zeros\n",
    "        if len(seq) > maxlen:\n",
    "            padded_sequences[i, :] = seq[:maxlen]\n",
    "        else:\n",
    "            padded_sequences[i, -len(seq):] = seq\n",
    "    return padded_sequences\n",
    "\n",
    "\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=max_sequence_length)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(book_df['label'])\n",
    "labels_one_hot = np.eye(len(set(encoded_labels)))[encoded_labels]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, labels_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define a simple CNN model\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels=1,\n",
    "                                              out_channels=n_filters,\n",
    "                                              kernel_size=(fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.embedding(x)\n",
    "        x = [torch.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        x = [torch.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in x]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "n_filters = 100\n",
    "filter_sizes = [2, 3, 4]\n",
    "output_dim = len(set(encoded_labels))\n",
    "dropout = 0.5\n",
    "weight_decay = 1e-4  # Regularization\n",
    "\n",
    "model = TextCNN(vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout)\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "lr = 0.0001\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.LongTensor(self.X[idx]), torch.FloatTensor(self.y[idx])\n",
    "\n",
    "train_data = TextDataset(X_train, y_train)\n",
    "val_data = TextDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "E, T, V = [], [], []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for texts, labels in train_loader:\n",
    "        predictions = model(texts)\n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluate after each epoch\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in val_loader:\n",
    "            predictions = model(texts)\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    E.append(epoch+1)\n",
    "    T.append(loss.item())\n",
    "    V.append(val_loss/len(val_loader))\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Training Loss: {loss.item()}, Validation Loss: {val_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(E, T)\n",
    "plt.plot(E, V)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the padded_sequences_test to a PyTorch tensor\n",
    "X_test = torch.tensor(padded_sequences_test, dtype=torch.long)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Predict the labels for the test data\n",
    "with torch.no_grad():\n",
    "    # Forward pass, get logit predictions\n",
    "    logits_test = model(X_test)\n",
    "\n",
    "    # Apply softmax to convert logits to probabilities\n",
    "    probabilities_test = torch.nn.functional.softmax(logits_test, dim=1)\n",
    "\n",
    "    # Get the predicted class labels\n",
    "    _, predicted_indices = torch.max(probabilities_test, dim=1)\n",
    "    predicted_labels = label_encoder.inverse_transform(predicted_indices.numpy())\n",
    "\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抑郁\n",
      "友爱\n",
      "欢乐\n",
      "感动\n",
      "腐败\n",
      "无助\n",
      "自省\n",
      "复仇\n"
     ]
    }
   ],
   "source": [
    "for i in b:\n",
    "    if i not in a:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags_emotion</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>奋斗</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tags_emotion  predicted_label\n",
       "26           奋斗                4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_test[book_test['tags_emotion'] == '奋斗']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_pca_embedding_dict = {k: tuple(v) for k, v in diction.items()}\n",
    "inverse_pca_embedding_dict = {v: k for k, v in tuple_pca_embedding_dict.items()}\n",
    "book_test_df['predicted_label'] = book_test_df['predicted_label'].apply(lambda x: inverse_pca_embedding_dict[tuple(x)] if tuple(x) in inverse_pca_embedding_dict else None)\n",
    "book_test_df = book_test_df[['tags_emotion', 'predicted_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags_emotion</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>幽默</td>\n",
       "      <td>搞笑组</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>温馨</td>\n",
       "      <td>情绪组</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>开心</td>\n",
       "      <td>情绪组</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>欢笑</td>\n",
       "      <td>情绪组</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>兴奋</td>\n",
       "      <td>情绪组</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>震撼</td>\n",
       "      <td>荒诞组</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>疑惑</td>\n",
       "      <td>思考组</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>自省</td>\n",
       "      <td>思考组</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>遗憾</td>\n",
       "      <td>思考组</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>悔恨</td>\n",
       "      <td>思考组</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tags_emotion predicted_label\n",
       "128           幽默             搞笑组\n",
       "80            温馨             情绪组\n",
       "188           开心             情绪组\n",
       "44            欢笑             情绪组\n",
       "4             兴奋             情绪组\n",
       "..           ...             ...\n",
       "66            震撼             荒诞组\n",
       "12            疑惑             思考组\n",
       "83            自省             思考组\n",
       "101           遗憾             思考组\n",
       "102           悔恨             思考组\n",
       "\n",
       "[192 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diction = {1:'搞笑组', 2:'情绪组', 3:'害怕组', 4:'正能量组', 5:'负能量组', 6:'烂片组', 7:'题材', 8:'主角路线', 9:'励志组', 10:'荒诞组', 11:'思考组', 12:'经典组'}\n",
    "\n",
    "df = book_test_df.sort_values('predicted_label')\n",
    "df['predicted_label'] = df['predicted_label'].map(diction)\n",
    "df = df[['tags_emotion', 'predicted_label']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('Book_output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.9832 - val_loss: 2.2969 - val_accuracy: 0.2333\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9748 - val_loss: 2.2967 - val_accuracy: 0.2333\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9748 - val_loss: 2.2968 - val_accuracy: 0.2333\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9832 - val_loss: 2.2972 - val_accuracy: 0.2333\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9832 - val_loss: 2.2971 - val_accuracy: 0.2333\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9748 - val_loss: 2.2974 - val_accuracy: 0.2333\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9832 - val_loss: 2.2974 - val_accuracy: 0.2333\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.9832 - val_loss: 2.2971 - val_accuracy: 0.2333\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9748 - val_loss: 2.2974 - val_accuracy: 0.2333\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9832 - val_loss: 2.2974 - val_accuracy: 0.2333\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9832 - val_loss: 2.2976 - val_accuracy: 0.2333\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9748 - val_loss: 2.2975 - val_accuracy: 0.2333\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9832 - val_loss: 2.2975 - val_accuracy: 0.2333\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9832 - val_loss: 2.2979 - val_accuracy: 0.2333\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9832 - val_loss: 2.2981 - val_accuracy: 0.2333\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0251 - accuracy: 0.9748 - val_loss: 2.2985 - val_accuracy: 0.2333\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9748 - val_loss: 2.2980 - val_accuracy: 0.2333\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9832 - val_loss: 2.2979 - val_accuracy: 0.2333\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9832 - val_loss: 2.2977 - val_accuracy: 0.2333\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9832 - val_loss: 2.2977 - val_accuracy: 0.2333\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9832 - val_loss: 2.2979 - val_accuracy: 0.2333\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9832 - val_loss: 2.2978 - val_accuracy: 0.2333\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0243 - accuracy: 0.9832 - val_loss: 2.2979 - val_accuracy: 0.2333\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9832 - val_loss: 2.2977 - val_accuracy: 0.2333\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9832 - val_loss: 2.2978 - val_accuracy: 0.2333\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9748 - val_loss: 2.2978 - val_accuracy: 0.2333\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0248 - accuracy: 0.9748 - val_loss: 2.2976 - val_accuracy: 0.2333\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9832 - val_loss: 2.2978 - val_accuracy: 0.2333\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0243 - accuracy: 0.9832 - val_loss: 2.2980 - val_accuracy: 0.2333\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0238 - accuracy: 0.9832 - val_loss: 2.2980 - val_accuracy: 0.2333\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9748 - val_loss: 2.2982 - val_accuracy: 0.2333\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9832 - val_loss: 2.2980 - val_accuracy: 0.2333\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9832 - val_loss: 2.2977 - val_accuracy: 0.2333\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9832 - val_loss: 2.2976 - val_accuracy: 0.2333\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0249 - accuracy: 0.9832 - val_loss: 2.2974 - val_accuracy: 0.2333\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9832 - val_loss: 2.2975 - val_accuracy: 0.2333\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9832 - val_loss: 2.2977 - val_accuracy: 0.2333\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 0.9748 - val_loss: 2.2975 - val_accuracy: 0.2333\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9832 - val_loss: 2.2976 - val_accuracy: 0.2333\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9832 - val_loss: 2.2978 - val_accuracy: 0.2333\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9748 - val_loss: 2.2977 - val_accuracy: 0.2333\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0241 - accuracy: 0.9748 - val_loss: 2.2979 - val_accuracy: 0.2333\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9832 - val_loss: 2.2979 - val_accuracy: 0.2333\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9748 - val_loss: 2.2979 - val_accuracy: 0.2333\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9832 - val_loss: 2.2983 - val_accuracy: 0.2333\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9832 - val_loss: 2.2981 - val_accuracy: 0.2333\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9832 - val_loss: 2.2985 - val_accuracy: 0.2333\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9832 - val_loss: 2.2985 - val_accuracy: 0.2333\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 0.9832 - val_loss: 2.2985 - val_accuracy: 0.2333\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0241 - accuracy: 0.9832 - val_loss: 2.2984 - val_accuracy: 0.2333\n",
      "{'loss': [0.024473704397678375, 0.024734552949666977, 0.024577610194683075, 0.02504396066069603, 0.02419225126504898, 0.024721862748265266, 0.023953057825565338, 0.024214506149291992, 0.02421603724360466, 0.024179697036743164, 0.024068545550107956, 0.024354293942451477, 0.024208785966038704, 0.024217400699853897, 0.024059288203716278, 0.025133954361081123, 0.024658078327775, 0.024074429646134377, 0.02402338944375515, 0.023952821269631386, 0.024299705401062965, 0.024009229615330696, 0.02428809553384781, 0.02419207990169525, 0.024110227823257446, 0.024012699723243713, 0.024762753397226334, 0.024484405294060707, 0.0242894496768713, 0.023796318098902702, 0.024417629465460777, 0.023974677547812462, 0.024032127112150192, 0.023940259590744972, 0.02487613447010517, 0.023984888568520546, 0.02409779652953148, 0.024491168558597565, 0.024188408628106117, 0.024026673287153244, 0.0240750964730978, 0.02409537509083748, 0.023937169462442398, 0.02390948310494423, 0.024459144100546837, 0.024216165766119957, 0.024037569761276245, 0.024245332926511765, 0.023875294253230095, 0.024132704362273216], 'accuracy': [0.9831932783126831, 0.9747899174690247, 0.9747899174690247, 0.9831932783126831, 0.9831932783126831, 0.9747899174690247, 0.9831932783126831, 0.9831932783126831, 0.9747899174690247, 0.9831932783126831, 0.9831932783126831, 0.9747899174690247, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9747899174690247, 0.9747899174690247, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9747899174690247, 0.9747899174690247, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9747899174690247, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9747899174690247, 0.9831932783126831, 0.9831932783126831, 0.9747899174690247, 0.9747899174690247, 0.9831932783126831, 0.9747899174690247, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831, 0.9831932783126831], 'val_loss': [2.296905994415283, 2.2967255115509033, 2.2967689037323, 2.2971982955932617, 2.2971158027648926, 2.2973978519439697, 2.297355890274048, 2.297121524810791, 2.297443389892578, 2.2974095344543457, 2.297579526901245, 2.297461748123169, 2.2975316047668457, 2.2978756427764893, 2.2980589866638184, 2.2984695434570312, 2.297950506210327, 2.2979001998901367, 2.297668695449829, 2.2977452278137207, 2.297863721847534, 2.2977588176727295, 2.297900438308716, 2.297663688659668, 2.2978196144104004, 2.2977871894836426, 2.297569513320923, 2.2977588176727295, 2.2980356216430664, 2.2980337142944336, 2.298175096511841, 2.2980000972747803, 2.297679901123047, 2.297624111175537, 2.2973546981811523, 2.297485113143921, 2.297656774520874, 2.297523260116577, 2.297560691833496, 2.2977774143218994, 2.2977449893951416, 2.297931432723999, 2.297905206680298, 2.2979235649108887, 2.2982592582702637, 2.29811429977417, 2.298509359359741, 2.2984509468078613, 2.2985212802886963, 2.2983591556549072], 'val_accuracy': [0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408, 0.23333333432674408]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/qiaochufeng/Desktop/c_clustering_emo/classification.ipynb 单元格 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qiaochufeng/Desktop/c_clustering_emo/classification.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/qiaochufeng/Desktop/c_clustering_emo/classification.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Plot training & validation accuracy values\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qiaochufeng/Desktop/c_clustering_emo/classification.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# plt.plot(history.history['accuracy'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qiaochufeng/Desktop/c_clustering_emo/classification.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# plt.plot(history.history['val_accuracy'])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qiaochufeng/Desktop/c_clustering_emo/classification.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# # Plot training & validation loss values\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qiaochufeng/Desktop/c_clustering_emo/classification.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# plt.plot(history.history['loss'])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/qiaochufeng/Desktop/c_clustering_emo/classification.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m-\u001b[39;49m history\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qiaochufeng/Desktop/c_clustering_emo/classification.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mModel loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qiaochufeng/Desktop/c_clustering_emo/classification.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "# Train the model, capturing the history\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
    "\n",
    "# The history object now contains the records of loss and accuracy for each epoch\n",
    "print(history.history)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# # plt.legend(['Train'], loc='upper left')\n",
    "# # plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot training & validation loss values\n",
    "# plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cq1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
